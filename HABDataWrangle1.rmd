---
title: "DataWrangles"
output: html_document
date: "2023-10-26"
---

### Library + Data Wrangling

```{r}
#Load the required library 
library(rEDM)
library(tidyverse)
library(googlesheets4)
library(tidyverse)
library(padr)
library(zoo)
library(spatstat)
library(forecast)
library(tseries)
library(dataRetrieval)
library(corrplot)
library(psych)
library(Hmisc)
library(reshape2)
library(plyr)
library(lubridate)
```

```{r}
vignette("dataRetrieval", package = "dataRetrieval")
```

## Data Wrangling

```{r}
#Charles River
#Reads data into R
CR2023 <- read_sheet('https://docs.google.com/spreadsheets/d/1R_HdqGuVMlfRyVPCzOw3CvbOjXDQfzFtDCMvKdj5vXU/edit?usp=sharing')

CR2022 <- read_sheet('https://docs.google.com/spreadsheets/d/1equdXHt4d-2s3r8YSsuHfpLufeRmGqno-SJqhcEwuNY/edit?usp=sharing')

CR2021 <- read_sheet('https://docs.google.com/spreadsheets/d/1CBzAD9uot_SPkY-JV-lJB6FSxSjlgXIS8A4jSY9SJjE/edit?usp=sharing')

CR2020 <- read_sheet('https://docs.google.com/spreadsheets/d/1fOV7JfJwLxddCaTsR0vkUodOZup4Y6HwVthMLzexe-I/edit?usp=sharing')

CR2019 <- read_sheet('https://docs.google.com/spreadsheets/d/1WGTUQ7F8wadO4RJ6PsfRsEnvwqNMdnAsdX71xqI9L-4/edit?usp=sharing')

CR2018 <- read_sheet('https://docs.google.com/spreadsheets/d/17AX8HNLXUCYz6YJIHRnb_rrKuzDudyAEq5WEhbSxOFQ/edit?usp=sharing')

CR2017 <- read_sheet('https://docs.google.com/spreadsheets/d/18xDJ9cLaZuj3JqhFsf847nSLMGKjfvWZmHWifsrPBq8/edit?usp=sharing')

CR2016 <- read_sheet('https://docs.google.com/spreadsheets/d/1rEOGM2H9cgVbFgVkIQZjIyzzl03fIywtkxBNg7GmXrY/edit?usp=sharing')

CR2015 <- read_sheet('https://docs.google.com/spreadsheets/d/11I8RQnOgZ9xmVEpaTVM_ELQZdTTp6T_305nwxkNI92I/edit?usp=sharing')

#Prints the data
```

```{r}
#bind rows
df_CR <- bind_rows(   CR2015,   CR2016,   CR2017 %>% rename(`time est`=time),   CR2018,   CR2019,   CR2020,   CR2021,   CR2022,   CR2023 )  
#combine data
df_CR <- df_CR %>%   mutate(hour = pmin(hour(`time est`),hour(`time edt`),na.rm=T),          minute = pmin(minute(`time est`),minute(`time edt`),na.rm=T)) %>%   select(date,hour,minute,chl=`chlorophyll (rfu)`,phy=`phycocyanin (rfu)`, ph=`ph`, Celsius =`temp c`,  spcond = `spcond (ms/cm)`, do = `do (mg/l)`,turb = `turbidity (fnu)` )
```

#add rows w/ missing NA values

```{r}
df_CR <- df_CR %>% pad()
```

#time-series+ggplot - chl + phy

```{r}
df_CR %>% group_by(date,hour) %>%   filter(year(date) >= 2021) %>%   summarise(across(c("chl","phy"),mean),.groups="keep") %>%   mutate(date= date+hours(hour)) %>%   ggplot(aes(x=date)) +    geom_path(aes(y=chl,color="chl")) +    geom_path(aes(y=phy,color="phy"))
```

#Plot ALL data

```{r}
df_CR %>% group_by(date,hour) %>%   filter(year(date) >= 2021) %>%   summarise(across(c("chl","phy", "ph", "Celsius", "spcond", "do", "turb"),mean),.groups="keep") %>%   mutate(date= date+hours(hour)) %>%   ggplot(aes(x=date)) +    geom_path(aes(y=chl,color="chl")) +    geom_path(aes(y=phy,color="phy")) +   geom_path(aes(y=ph,color="ph")) +    geom_path(aes(y=Celsius,color="Celsius")) +   geom_path(aes(y=spcond,color="spcond")) +   geom_path(aes(y=do,color="do")) +   geom_path(aes(y=turb,color="turb"))
```

#Take Away NA Values + Aggregate Daily Mean

```{r}
#Take away NA values 
df_CR <- na.omit(df_CR) 
#Aggregate Daily Mean
ag_df_CR <-df_CR %>%    group_by(date) %>%   summarise(chl=mean(chl), phy=mean(phy), ph=mean(ph), Celsius=mean(Celsius), spcond=mean(spcond), do=mean(do), turb=mean(turb)) 
 #Omit NA Values
ag_df_CR <- ag_df_CR %>% pad()   
#Plot  
ag_df_CR %>% group_by(date) %>%   filter(year(date) >= 2021) %>%   ggplot(aes(x=date)) +    geom_path(aes(y=chl,color="chl")) +    geom_path(aes(y=phy,color="phy")) +   geom_path(aes(y=ph,color="ph")) +    geom_path(aes(y=Celsius,color="Celsius")) +   geom_path(aes(y=spcond,color="spcond")) +   geom_path(aes(y=do,color="do")) +   geom_path(aes(y=turb,color="turb"))
```

### ARIMA

```{r}
#**Monthly Only?**

class(ag_df_CR)

#Fit Dataset
rate <- ts(ag_df_CR[,'chl'],start = c(2015,5), frequency = 365 )

#Grab Data
autoplot(rate) + ggtitle ("Aggregate CR") + ylab("CR")

#Build ARIMA Model
fit_ARIMA <-auto.arima(rate, seasonal = TRUE)
print(summary(fit_ARIMA))
checkresiduals(fit_ARIMA)

#Forecast
fcast <- forecast(fit_ARIMA, h =1) #h = amount of periods ahead
autoplot
plot(fcast)
print(summary(fcast))

#Fitting an auto.arima model in R using the Forecast package
#fit_basic1<- auto.arima(df_CR,xreg=trainREG_TS)
#forecast_1<-forecast(fit_basic1,xreg = testREG_TS)

```

### PCF

```{r}
?pcf

#**runpcf - Dietze**
p <- pcf(Kest(df_CR$chl))
plot(p)

my_array <-simplify2array(df_CR$chl)
```

### PACF

```{r}
#Take away NA values 
ag_df_CR <- na.omit(ag_df_CR) 
pacf(df_CR$chl, lag.max = 7)

```

```{r}
#**dietze**
ag_df_CR_2021 <- ag_df_CR %>% filter(year(date)==2021)

pacf2021 <- ag_df_CR %>% 
  filter(year(date)==2021) %>%
  pull(chl) %>%
  pacf(lag.max=45)


pacf2021 <- pacf(pacf2021$chl, lag.max = 7)
#correlation at speicifc lag corrected for short lag
pacf2021 <- pacf(pacf2021$chl, lag.max = 30)

```

### Coefficients of Correlation

```{r}

describe(ag_df_CR)  #this will flag those variables that are categorical with an asterix
numericag <- char2numeric(ag_df_CR)  #this makes all numeric
cor_data = cor(numericag)
cor_data <- cor_data[-c(1),-c(1) ] #remove 1st row + column
print("Correlation matrix")
print(cor_data)
corrplot(cor_data, method="number")


rcorr(as.matrix(numericag[-1,-1]), type = c("pearson"))

#chl and do are very correlated
#a lot of chl fair amount of photosynthesis 
#euphotic zone
#make another chat 


```

### USGS

```{r}

library(dataRetrieval)

outputData <- readNWISdata(huc = "01090001",
                    period = "P3231D",
                    siteStatus = "all",
                    outputDataTypeCd = c("iv","dv","pk","sv","gw","qw","id","aw","ad"),
                    service="site")
print(outputData)

outputDatacoords <- readNWISdata(huc = "01090001",
                    period = "P3231D",
                    siteStatus = "all",
                    outputDataTypeCd = c("iv","dv","pk","sv","gw","qw","id","aw","ad"),
                    service="site")

library(dataRetrieval)

outputDataDaily <- readNWISdata(huc = "01090001",
                    period = "P30D",
                    siteStatus = "all",
                    service="dv")

```

```{r}
#Create table w/ coords + site #

outputDatawrangle <- 
data.frame(outputDatacoords$site_no, outputDatacoords$dec_lat_va, outputDatacoords$dec_long_va, outputDatacoords$station_nm)

outputDatawrangle2 <- outputDatawrangle %>% distinct() #remove duplicate data

```

```{r}
USGSoutput<- 
right_join(outputDataDaily, outputDatawrangle2, by = c("site_no"  = "outputDatacoords.site_no"))

```

**RENAME COLUMNS**

Export

```{r}
write_csv(USGSoutput, file = "USGSoutput.csv") 
```

### MWRA Non-CSO

```{r}
CR_bacteria <- read_sheet('https://docs.google.com/spreadsheets/d/1V1DJc4er2gctuRN2bv3u3Db0bGxz566ec8j6xmXFZ70/edit?usp=sharing', range = 'cr_bacteria')
```

```{r}
# Pull raw CRBACTERIA
fname_CR_bacteria <- "./data/raw/CR_bacteria.Rdata"

if(!file.exists(fname_CR_bacteria)){
  CR_bacteria <- read_sheet('https://docs.google.com/spreadsheets/d/1V1DJc4er2gctuRN2bv3u3Db0bGxz566ec8j6xmXFZ70/edit?usp=sharing', range = 'cr_bacteria')
  save(CR_bacteria,file=fname_CR_bacteria)
}else{
  load(fname_CR_bacteria)
}
```

```{r}

## Wrangle

v_new_names <- c(
  "Project_ID",
  "Region",
  "Subregion",
  "DEP_Segment",
  "Station ID",
  "Date",
  "Depth_category",
  "Sample_depth",
  "Enterococcus",
  "Enterococcus_condition",
  "E_coli",
  "E_coli_condition",
  "coliform",
  "coliform_condition",
  "Rainfall_1d",
  "Rainfall_2d",
  "Rainfall_3d"
)

colnames(CR_bacteria) <- as.character(CR_bacteria[5,]) #set header
CR_bacteria <- CR_bacteria[-c(1:5), ] #Remove 1st 5 Rows
#rename columns

CR_bacteria <- CR_bacteria %>% 
  set_names(v_new_names) %>%
  mutate(Date = map_vec(Date,as.Date))
```

```{r}

#FIX DATE

CR_secchi <- read_sheet('https://docs.google.com/spreadsheets/d/1fW4_60i-SYkdTPlFQQdN0b5nlZirc2uQyjDN_dvWA18/edit?usp=sharing', range = 'cr_secchi')
colnames(CR_secchi) <- as.character(CR_secchi[5,])#set header
CR_secchi <- CR_secchi[-c(1:5), ] #Remove 1st 5 Rows
#rename columns
CR_secchi <- CR_secchi %>% 
       rename("Date" = 6)

#CRPHYSICAL
CR_physical <- read_sheet('https://docs.google.com/spreadsheets/d/1P5kzPHFABPTKffxM2yQBTIQWq9NAmnGd3PF6kOsSFNU/edit?usp=sharing', range = 'cr_physical')
colnames(CR_physical) <- as.character(CR_physical[5,])#set header
CR_physical <- CR_physical[-c(1:5), ] #Remove 1st 5 Rows
#rename columns
CR_physical <- CR_physical %>% 
       rename("Date" = 6)

#CRNUTRIENTS
CR_nutrients <- read_sheet('https://docs.google.com/spreadsheets/d/1kPHmgJUHF7GtNJJDme_gWgB7hTS7i6SE7pqazChKMZ4/edit?usp=sharing')
colnames(CR_nutrients) <- as.character(CR_nutrients[4,])#set header
CR_nutrients <- CR_nutrients[-c(1:4), ] #Remove 1st 4 Rows
#rename columns
CR_nutrients <- CR_nutrients %>% 
       rename("Date" = 6)





```

```{r}
MWRAMap_stations <- read_sheet('https://docs.google.com/spreadsheets/d/1UYcDAnvZI8dbvf5ENLHLA8HRtX-Y_epLCfOeUsCB8yQ/edit?usp=sharing', range = 'Map_stations')

```

CR_nutrients \<- right_join(CR_nutrients, MWRAMap_stations, by = c("Station ID" = "STAT_ID" ))

```{r}

#Combine DFs

CR_bacteria <-  right_join(CR_bacteria , MWRAMap_stations,  by = c("Station ID"  =  "STAT_ID" ))


CR_physical <- right_join(CR_physical, MWRAMap_stations,  by = c("Station ID"  =  "STAT_ID" ))
                          
CR_secchi <- right_join(CR_secchi, MWRAMap_stations,  by = c("Station ID"  =  "STAT_ID" ))

CR_nutrients <- right_join(CR_nutrients, MWRAMap_stations,  by = c("Station ID"  =  "STAT_ID" ))



```

```{r}
CR_bacteria <- data.frame(lapply(CR_bacteria, as.character))
CR_physical <- data.frame(lapply(CR_physical, as.character))
CR_secchi <- data.frame(lapply(CR_secchi, as.character))
CR_nutrients <- data.frame(lapply(CR_nutrients, as.character))


write.csv(CR_bacteria, file = "CR_bacteria.csv")
write.csv(CR_physical, file = "CR_physical.csv")
write.csv(CR_secchi, file = "CR_secchi.csv")
write.csv(CR_nutrients, file = "CR_nutrients.csv")
```

### CRWA

```{r}
CRWAdata <- read_sheet('https://docs.google.com/spreadsheets/d/1pJxZbbWJUtoLKJ9lX6DA09esBOZdVCDiB4Ztd92hrtE/edit?usp=sharing')
```

```{r}


 # do something about Results that are "<10.0". turn into 0 for now?

#CRWAdata <- CRWAdata %>%
  #mutate( = ifelse(Value == "<10.0", 0, as.numeric(Value)))

CRWAdata_wide <- CRWAdata %>%
  select(Site_ID,Date_Collected,
         Time_Collected,Component_ID,Reporting_Result) %>%
  group_by(Site_ID,Date_Collected,Time_Collected,Component_ID) %>%
  summarise(Reporting_Result = mean(Reporting_Result,na.rm=T),.groups = "keep") %>%
  pivot_wider(names_from= Component_ID,values_from=Reporting_Result)


#Data types
CRWAtypes <- CRWAdata %>% distinct(CRWAdata$Component_ID) #remove duplicate data
Component_ID2 <- CRWAtypes

```

```{r}
#SITE IDs
CRWAMap_stations <- read_sheet('https://docs.google.com/spreadsheets/d/1mkNv-07loU1pDz8SWE0spoa-phkgEL65I69Hi26P3Rc/edit?usp=sharing')
CRWAMap_stations <- CRWAMap_stations[-c(2,6:23)] #remove columns


```

```{r}
#Combine DFs
CRWAfinal <-  
right_join(CRWAdata_wide , CRWAMap_stations,  by = c("Site_ID"  = "Site_ID"))

write.csv(CRWAfinal, file = "CRWAfinal.csv")
```

### CRPD

```{r}

CRPDPhosphorus <- read_sheet('https://docs.google.com/spreadsheets/d/1_kNmoQZGYHPl2WIFnaRyezArj6fqWIYX7enTjzOKwH0/edit?usp=sharing', range = 'Total Phosphorus') 

CRPDTotalSuspendedSolids <- read_sheet('https://docs.google.com/spreadsheets/d/1_kNmoQZGYHPl2WIFnaRyezArj6fqWIYX7enTjzOKwH0/edit?usp=sharing', range = 'Total Suspended Solids')

CRPDAmmonia <- read_sheet('https://docs.google.com/spreadsheets/d/1_kNmoQZGYHPl2WIFnaRyezArj6fqWIYX7enTjzOKwH0/edit?usp=sharing', range = 'Ammonia')

CRPDDissolvedOxygen <- read_sheet('https://docs.google.com/spreadsheets/d/1_kNmoQZGYHPl2WIFnaRyezArj6fqWIYX7enTjzOKwH0/edit?usp=sharing', range = 'Dissoloved Oxygen')

CRPDEColi <- read_sheet('https://docs.google.com/spreadsheets/d/1_kNmoQZGYHPl2WIFnaRyezArj6fqWIYX7enTjzOKwH0/edit?usp=sharing', range = 'EColi')

```

```{r}
#Join all Dates + Data

join_all(list(CRPDPhosphorus, CRPDAmmonia, CRPDDissolvedOxygen, CRPDEColi, CRPDTotalSuspendedSolids), by='Date', type='left')


```

### Max Paper

```{r}
MaxCounts <-  read_sheet('https://docs.google.com/spreadsheets/d/1ZuHtqJuvNgF3Je60vyb9ZhGCF8d617ag4z3uWywtkfA/edit?usp=sharing')

Max2017 <- read_sheet('https://docs.google.com/spreadsheets/d/1OZuFPC7K1xMcUtSPy2sQ8rcaa1TeAXAQFdaPztrQ2tc/edit?usp=sharing')

Max2018Chl <- read_sheet('https://docs.google.com/spreadsheets/d/1mp1-lz7kCVdtAkhHKyeQCNVAi6lE3kJdtOEQo1zdLV0/edit?usp=sharing')

Max2018TurbChl <- read_sheet('https://docs.google.com/spreadsheets/d/1Xo7ERxFApiiCgwb1ZmKJTQ-HQWpES6xrSeJRZmdFFO8/edit?usp=sharing')

#need to combine above 2

```

```{r}
MDPH <- read_sheet('https://docs.google.com/spreadsheets/d/1a6U6dOQEYg8FF1lN6KjcE5uw4aM_lXRcxj7vdOqX4c4/edit?usp=sharing')
```

### MWRA CSO Data

```{r}

MWRACSOData2016 <- read_sheet('https://docs.google.com/spreadsheets/d/1BF5lMyYrnILoS-rySwTGILiaqYfxA5-Pz5P2xUmOIq8/edit?usp=sharing')

MWRACSOData <- read_sheet('https://docs.google.com/spreadsheets/d/1PRu1yvIuxOnMyazAVkXGv7dkOKUClNxl7CrvrctPREU/edit?usp=sharing')



```

```{r}


#Extract Date
MWRACSOData$Date <- as.Date(MWRACSOData$`Start Time`, format = "%m/%d/%Y")


#Remove Excess Charecters

#Remove "Treated" in Volume Column
MWRACSOData$`Volume (MG)` <- gsub("Treated","",as.character(MWRACSOData$`Volume (MG)`))

#Remove "min" in Minutes Column

MWRACSOData$Minutes <- gsub("min","",as.character(MWRACSOData$Minutes))

#Remove Rows w/ "*"
MWRACSOData <- MWRACSOData %>% filter(!grepl("\\*", MWRACSOData$Duration))

#Replace NA w/ 0
MWRACSOData$Minutes[is.na(MWRACSOData$Minutes)] <- 0

#Make Duration Column
MWRACSOData$Minutes <- as.numeric(MWRACSOData$Minutes)
MWRACSOData$Hours <- as.numeric(MWRACSOData$Hours)

MWRACSOData$CombinedMinutes <- MWRACSOData$Minutes + (MWRACSOData$Hours * 60)

#Remove Columns 

MWRACSOData <- MWRACSOData[-c(4:10)]

#Check Dates

unique_dates <- unique(MWRACSOData$Date)


# Sanity Check: CombinedMinutes to numeric and Date to Date format
MWRACSOData <- MWRACSOData %>%
  mutate(CombinedMinutes = as.numeric(CombinedMinutes),
         Date = as.Date(Date))

MWRACSOData <- MWRACSOData %>%
  mutate(`Volume (MG)` = as.numeric(`Volume (MG)`),
         Date = as.Date(Date))

# Group by Date and calculate the sum of CombinedMinutes



MWRACSOData2 <- 
aggregate(MWRACSOData$CombinedMinutes, by=list(MWRACSOData$Date, MWRACSOData$`Outfall Location`), FUN = sum) 


MWRACSOData3 <- 
aggregate(MWRACSOData$`Volume (MG)`, by=list(MWRACSOData$Date, MWRACSOData$`Outfall Location`), FUN = sum) 

MWRACSOData20162 <- 
aggregate(MWRACSOData2016$`Duration (Min)`, by=list(MWRACSOData2016$Date, MWRACSOData2016$CSOName), FUN = sum) 

MWRACSOData20163 <- 
aggregate(MWRACSOData2016$`Volume (MG)`, by=list(MWRACSOData2016$Date, MWRACSOData2016$CSOName), FUN = sum) 


# Rename a column using colnames

colnames(MWRACSOData2)[1:3] <- c("Date","Outfall Location", "Total Minutes")

colnames(MWRACSOData20162)[1:3] <- c("Date","Outfall Location", "Total Minutes")

colnames(MWRACSOData3)[1:3] <- c("Date","Outfall Location", "Volume")

colnames(MWRACSOData20163)[1:3] <- c("Date","Outfall Location", "Volume")

#Set Columns to Be The Same

MWRACSOData <- MWRACSOData[-c(1,4,5,7)]

MWRACSOData2016 <- MWRACSOData2016[-c(3:8)]




#Make New Names

MWRA_new_names <- c(
  "CSO_ID",
  "Outfall Location",
  "Date"
)

MWRA2016_new_names <- c(
  "CSO_ID",
  "Outfall Location",
  "Date"
)

MWRACSOData <- MWRACSOData %>% 
  set_names(MWRA_new_names)
  
MWRACSOData2016 <- MWRACSOData2016 %>% 
  set_names(MWRA2016_new_names)

#Fix Date Format

MWRACSOData$Date <- format(as.Date(MWRACSOData$Date, format=
                           "%Y-%m-%d"          ), "%m-%d-%Y")

#Merge Columns 

MergedMWRACSO <- rbind(MWRACSOData,MWRACSOData2016)

#Order Date

MergedMWRACSO[order(as.Date(MergedMWRACSO$Date, format="%m/%d/%Y")),]

#Fix Date Formats of Future Joins
MWRACSOData2$Date <- format(as.Date(MWRACSOData2$Date, format=
                           "%Y-%m-%d"          ), "%m-%d-%Y")


MWRACSOData3$Date <- format(as.Date(MWRACSOData3$Date, format=
                           "%Y-%m-%d"          ), "%m-%d-%Y")

# Perform the joins

MergedMWRACSO <- merge(MergedMWRACSO, MWRACSOData2[, c("Date", "Outfall Location", "Total Minutes")], 
                       by.x = c("Date", "Outfall Location"), 
                       by.y = c("Date", "Outfall Location"), all.x = TRUE)

MergedMWRACSO <- merge(MergedMWRACSO, MWRACSOData20162[, c("Date", "Outfall Location", "Total Minutes")], 
                       by.x = c("Date", "Outfall Location"), 
                       by.y = c("Date", "Outfall Location"), all.x = TRUE)

# Combine the columns using coalesce
MergedMWRACSO <- MergedMWRACSO %>%
  mutate(TotalMinutes_combined = coalesce(`Total Minutes.x`, `Total Minutes.y`))


# Drop the individual columns if you no longer need them
MergedMWRACSO <- MergedMWRACSO %>%
  select(-`Total Minutes.x`, -`Total Minutes.y`)


MergedMWRACSO <- merge(MergedMWRACSO, MWRACSOData3[, c("Date", "Outfall Location", "Volume")], 
                       by.x = c("Date", "Outfall Location"), 
                       by.y = c("Date", "Outfall Location"), all.x = TRUE)

MergedMWRACSO <- merge(MergedMWRACSO, MWRACSOData20163[, c("Date", "Outfall Location", "Volume")], 
                       by.x = c("Date", "Outfall Location"), 
                       by.y = c("Date", "Outfall Location"), all.x = TRUE)

MergedMWRACSO <- MergedMWRACSO %>%
  mutate(Volume_combined = coalesce(`Volume.x`, `Volume.y`))


# Drop the individual columns if you no longer need them
MergedMWRACSO <- MergedMWRACSO %>%
  select(-`Volume.x`, -`Volume.y`)


```

#Need to Add "Data Collection Ends at 2020" Column

```{r}

MWRACSOCoords <- read_sheet('https://docs.google.com/spreadsheets/d/1O9RONCW0lGEsPrt-srZU8M4xeNxDM3hJmkA1IWL2mW4/edit?usp=sharing')

MWRACSOCoords2 <- read_sheet('https://docs.google.com/spreadsheets/d/18PK0CcX6Ye5RZJtVUI8mmiaRwLIpRNIzGCwOupSqf-k/edit?usp=sharing')


```

```{r}

MWRACSOFinal <-  
left_join(MergedMWRACSO , MWRACSOCoords ,  by = c("CSO_ID" = "OUTFALL"  ))

#MWRACSOCoords2$OUTFALL_ID <- as.character(MWRACSOCoords2$OUTFALL_ID )

#MWRACSOFinal <-  
#left_join(MergedMWRACSO , MWRACSOCoords2 ,  by = c("CSO_ID" = "OUTFALL_ID"  ))
```

```{r}
write_csv(MWRACSOFinal, file = "MWRACSOs.csv") 
```

### 

### Precip

```{r}

```

### CAMCSO

```{r}
CAMCSO2015 <- read_sheet('https://docs.google.com/spreadsheets/d/1TWsZX6Mqtobc_Ty6TOqNnk3uJ_XYa3eR_uh-OOqPo_I/edit?usp=sharing')
```
